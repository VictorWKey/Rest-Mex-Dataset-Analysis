# üöÄ Inicio R√°pido - Data Augmentation

## Configuraci√≥n en 3 Pasos

### 1Ô∏è‚É£ Selecciona tu m√©todo

Edita la celda **1.5** del notebook:

```python
# Para desarrollo r√°pido (recomendado):
AUGMENTATION_METHOD = 'eda'

# Para m√°xima calidad (lento):
AUGMENTATION_METHOD = 'backtranslation'
```

### 2Ô∏è‚É£ Instala dependencias (solo si usas back-translation)

```bash
# Solo si elegiste AUGMENTATION_METHOD = 'backtranslation'
pip install torch transformers sacremoses
```

### 3Ô∏è‚É£ Ejecuta el notebook

```bash
# Instalar dependencias base
pip install -r requirements.txt

# Ejecutar Jupyter
jupyter notebook 02_model_pipeline.ipynb
```

---

## ‚ö° Comparaci√≥n R√°pida

| M√©todo | Tiempo | GPU | Calidad | Recomendado para |
|--------|--------|-----|---------|------------------|
| **EDA** | 10 min | ‚ùå No | ‚≠ê‚≠ê‚≠ê‚≠ê | Desarrollo r√°pido, CPU |
| **Back-Translation** | 2-4 hrs | ‚úÖ S√≠ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Producci√≥n, GPU disponible |

---

## üéØ Casos de Uso

### Caso 1: "Tengo 2-4 horas y CPU"
```python
AUGMENTATION_METHOD = 'eda'
```
‚úÖ Perfecto. EDA es r√°pido y eficiente en CPU.

### Caso 2: "Tengo GPU y quiero m√°xima calidad"
```python
AUGMENTATION_METHOD = 'backtranslation'
BACKTRANSLATION_CONFIG = {'languages': ['en', 'fr', 'de'], 'device': 'cuda'}
```
‚úÖ Back-translation con m√∫ltiples idiomas.

### Caso 3: "Tengo CPU pero puedo esperar 4+ horas"
```python
AUGMENTATION_METHOD = 'backtranslation'
BACKTRANSLATION_CONFIG = {'languages': ['en'], 'device': 'cpu'}
```
‚ö†Ô∏è Solo usa ingl√©s para reducir tiempo.

---

## üìÇ Archivos Generados (ambos m√©todos)

Ambos m√©todos generan los mismos archivos de salida:

```
embeddings_complete.csv       ‚Üê Todos los embeddings + labels
embeddings_with_split.csv      ‚Üê Con columna train/test
model_polarity.pkl             ‚Üê Modelo de polaridad (sklearn)
model_type.pkl                 ‚Üê Modelo de tipo (sklearn)
models_metadata.json           ‚Üê Metadata (incluye m√©todo usado)
```

Todos compatibles con Scala/Spark MLlib.

---

## üêõ Problemas Comunes

### "ModuleNotFoundError: No module named 'transformers'"
```bash
pip install torch transformers sacremoses
```

### "Back-translation muy lento en CPU"
Cambia a:
```python
AUGMENTATION_METHOD = 'eda'
```

### "CUDA out of memory"
```python
BACKTRANSLATION_CONFIG = {'languages': ['en'], 'device': 'cpu'}
```

---

## üìö Documentaci√≥n Completa

Para m√°s detalles, ver:
- `README_AUGMENTATION.md` - Gu√≠a completa con ejemplos
- `CAMBIOS_AUGMENTATION.md` - Cambios t√©cnicos implementados
- `README_SCALA.md` - C√≥mo usar los archivos generados en Scala

---

## ‚úÖ Checklist Pre-Ejecuci√≥n

- [ ] Elegir m√©todo en celda 1.5: `AUGMENTATION_METHOD = 'eda'` o `'backtranslation'`
- [ ] Si usas back-translation: `pip install torch transformers sacremoses`
- [ ] Instalar: `pip install -r requirements.txt`
- [ ] Verificar tiempo disponible: EDA ~10-15 min, Back-translation ~2-4 hrs
- [ ] Ejecutar notebook completo

---

## üí° Recomendaci√≥n

**Para la mayor√≠a de casos, usa EDA:**
- ‚úÖ 10x m√°s r√°pido
- ‚úÖ No requiere GPU
- ‚úÖ Resultados muy buenos
- ‚úÖ Ideal para desarrollo iterativo

**Usa back-translation solo si:**
- Tienes GPU disponible
- Necesitas m√°xima calidad
- Puedes esperar 2-4 horas
- Es para modelo de producci√≥n final
