{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d0b73f",
   "metadata": {},
   "source": [
    "# Rest-Mex Dataset - Modelo de Predicción\n",
    "## Data Augmentation + Balanceo + Modelos de Clasificación\n",
    "\n",
    "**Estrategia:**\n",
    "- EDA para clases minoritarias (1, 2, 3)\n",
    "- Undersampling de clase mayoritaria (5)\n",
    "- Embeddings con MiniLM multilingüe (rápido)\n",
    "- RandomForest/GradientBoosting (compatibles con Scala)\n",
    "- Exportar embeddings a CSV para uso en Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ba4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda' if __import__('torch').cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbebda43",
   "metadata": {},
   "source": [
    "## 1. Carga y Análisis de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d03f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 208,051\n",
      "\n",
      "Polaridad original:\n",
      "Polarity\n",
      "0      5441\n",
      "1      5496\n",
      "2     15519\n",
      "3     45034\n",
      "4    136561\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Tipo original:\n",
      "Type\n",
      "Restaurant    86720\n",
      "Attractive    69921\n",
      "Hotel         51410\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/Rest-Mex_2025_train.csv')\n",
    "df = df[['Review', 'Polarity', 'Type']].dropna()\n",
    "df['Polarity'] = df['Polarity'].astype(int) - 1  # 0-4 para el modelo\n",
    "\n",
    "print(f\"Total: {len(df):,}\")\n",
    "print(f\"\\nPolaridad original:\\n{df['Polarity'].value_counts().sort_index()}\")\n",
    "print(f\"\\nTipo original:\\n{df['Type'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5494be",
   "metadata": {},
   "source": [
    "## 1.5. Configuración de Data Augmentation\n",
    "**Selecciona el método de augmentation para clases minoritarias:**\n",
    "- `'eda'`: Easy Data Augmentation (rápido, ~5-10 min)\n",
    "- `'backtranslation'`: Back-translation multi-idioma (lento, ~2-4 horas en CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ad069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CONFIGURACIÓN DE DATA AUGMENTATION\n",
    "# ==========================================\n",
    "\n",
    "AUGMENTATION_METHOD = 'eda'  # Opciones: 'eda' o 'backtranslation'\n",
    "\n",
    "# Configuración para EDA\n",
    "EDA_CONFIG = {\n",
    "    'alpha_sr': 0.15,  # Porcentaje para synonym replacement\n",
    "    'alpha_ri': 0.15,  # Porcentaje para random insertion\n",
    "    'alpha_rs': 0.15,  # Porcentaje para random swap\n",
    "    'p_rd': 0.1        # Probabilidad de random deletion\n",
    "}\n",
    "\n",
    "# Configuración para Back-Translation\n",
    "BACKTRANSLATION_CONFIG = {\n",
    "    'languages': ['en', 'fr', 'de'],  # Idiomas intermedios\n",
    "    'device': 'cpu'  # 'cuda' si tienes GPU disponible\n",
    "}\n",
    "\n",
    "# Estrategia de balanceo (misma para ambos métodos)\n",
    "TARGET_SAMPLES = {\n",
    "    0: 30000,  # Pol 1: 5K → 30K (6x)\n",
    "    1: 30000,  # Pol 2: 5K → 30K (6x)\n",
    "    2: 40000,  # Pol 3: 15K → 40K (2.7x)\n",
    "    3: 40000,  # Pol 4: 45K → 40K (undersampling)\n",
    "    4: 50000   # Pol 5: 136K → 50K (undersampling)\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CONFIGURACIÓN DE DATA AUGMENTATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Método seleccionado: {AUGMENTATION_METHOD.upper()}\")\n",
    "if AUGMENTATION_METHOD == 'eda':\n",
    "    print(f\"  • Configuración EDA: {EDA_CONFIG}\")\n",
    "else:\n",
    "    print(f\"  • Idiomas: {BACKTRANSLATION_CONFIG['languages']}\")\n",
    "    print(f\"  • Device: {BACKTRANSLATION_CONFIG['device']}\")\n",
    "print(f\"\\nObjetivos de balanceo:\")\n",
    "for pol, target in TARGET_SAMPLES.items():\n",
    "    print(f\"  Polaridad {pol+1}: → {target:,}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5c2482",
   "metadata": {},
   "source": [
    "## 3. Aplicar Data Augmentation\n",
    "**Aplicando el método seleccionado en la configuración**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e560f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INICIANDO DATA AUGMENTATION CON EDA\n",
      "======================================================================\n",
      "Técnicas: Synonym Replacement, Random Insertion, Random Swap, Random Deletion\n",
      "\n",
      "  Polaridad 1: 5,441 → 30,000 (generando 24,559 muestras)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c562a533294a4ba08ccbab5f4e4e69f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Augmentando Pol 1:   0%|          | 0/24559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Completado: 30,000 muestras totales\n",
      "\n",
      "  Polaridad 2: 5,496 → 30,000 (generando 24,504 muestras)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcd68461e7144ccaa8c511348145805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Augmentando Pol 2:   0%|          | 0/24504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Completado: 30,000 muestras totales\n",
      "\n",
      "  Polaridad 3: 15,519 → 40,000 (generando 24,481 muestras)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb296627ba24ad88d76b7e01db03997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Augmentando Pol 3:   0%|          | 0/24481 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Completado: 40,000 muestras totales\n",
      "\n",
      "  Polaridad 4: 45,034 (sin cambios)\n",
      "  Polaridad 5: 136,561 (se aplicará undersampling)\n",
      "\n",
      "======================================================================\n",
      "RESUMEN DESPUÉS DE AUGMENTATION\n",
      "======================================================================\n",
      "  Polaridad 1: 30,000\n",
      "  Polaridad 2: 30,000\n",
      "  Polaridad 3: 40,000\n",
      "  Polaridad 4: 45,034\n",
      "  Polaridad 5: 136,561\n",
      "\n",
      "Total: 281,595\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def augment_class(df, polarity, target_size, method='eda'):\n",
    "    \"\"\"\n",
    "    Aumenta una clase usando el método especificado\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con los datos\n",
    "        polarity: Clase de polaridad a aumentar (0-4)\n",
    "        target_size: Número objetivo de muestras\n",
    "        method: 'eda' o 'backtranslation'\n",
    "    \"\"\"\n",
    "    class_df = df[df['Polarity'] == polarity].copy()\n",
    "    current = len(class_df)\n",
    "    needed = target_size - current\n",
    "    \n",
    "    if needed <= 0:\n",
    "        print(f\"  Polaridad {polarity+1}: {current:,} → {target_size:,} (sin cambios)\")\n",
    "        return class_df\n",
    "    \n",
    "    print(f\"  Polaridad {polarity+1}: {current:,} → {target_size:,} (generando {needed:,} muestras con {method.upper()})\")\n",
    "    \n",
    "    augmented = []\n",
    "    samples = class_df.sample(n=needed, replace=True)\n",
    "    \n",
    "    if method == 'eda':\n",
    "        # EDA: Rápido\n",
    "        for idx, row in tqdm(samples.iterrows(), total=len(samples), desc=f\"    Augmentando Pol {polarity+1}\"):\n",
    "            new_row = row.copy()\n",
    "            aug_texts = eda(\n",
    "                row['Review'], \n",
    "                alpha_sr=EDA_CONFIG['alpha_sr'],\n",
    "                alpha_ri=EDA_CONFIG['alpha_ri'],\n",
    "                alpha_rs=EDA_CONFIG['alpha_rs'],\n",
    "                p_rd=EDA_CONFIG['p_rd'],\n",
    "                num_aug=1\n",
    "            )\n",
    "            new_row['Review'] = aug_texts[0]\n",
    "            augmented.append(new_row)\n",
    "    \n",
    "    elif method == 'backtranslation':\n",
    "        # Back-Translation: Lento pero más preciso\n",
    "        # Cargar modelos solo una vez\n",
    "        if 'bt_models' not in globals():\n",
    "            global bt_models, bt_tokenizers\n",
    "            bt_models, bt_tokenizers = load_backtranslation_models()\n",
    "        \n",
    "        for idx, row in tqdm(samples.iterrows(), total=len(samples), desc=f\"    Augmentando Pol {polarity+1}\"):\n",
    "            new_row = row.copy()\n",
    "            aug_texts = back_translate(\n",
    "                row['Review'],\n",
    "                source_lang='es',\n",
    "                target_langs=BACKTRANSLATION_CONFIG['languages'],\n",
    "                models=bt_models,\n",
    "                tokenizers=bt_tokenizers,\n",
    "                device=BACKTRANSLATION_CONFIG['device']\n",
    "            )\n",
    "            # Usar la primera traducción disponible\n",
    "            if aug_texts:\n",
    "                new_row['Review'] = aug_texts[0]\n",
    "                augmented.append(new_row)\n",
    "    \n",
    "    result = pd.concat([class_df, pd.DataFrame(augmented)], ignore_index=True)\n",
    "    print(f\"    ✓ Completado: {len(result):,} muestras totales\\n\")\n",
    "    return result\n",
    "\n",
    "# ==========================================\n",
    "# EJECUTAR AUGMENTATION\n",
    "# ==========================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"INICIANDO DATA AUGMENTATION CON {AUGMENTATION_METHOD.upper()}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if AUGMENTATION_METHOD == 'eda':\n",
    "    print(\"Técnicas: Synonym Replacement, Random Insertion, Random Swap, Random Deletion\")\n",
    "elif AUGMENTATION_METHOD == 'backtranslation':\n",
    "    print(f\"Idiomas intermedios: {BACKTRANSLATION_CONFIG['languages']}\")\n",
    "    print(f\"Device: {BACKTRANSLATION_CONFIG['device']}\")\n",
    "    print(\"⚠️  ADVERTENCIA: Este método puede tardar 2-4 horas en CPU\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Augmentar clases minoritarias según TARGET_SAMPLES\n",
    "df_pol0 = augment_class(df, 0, TARGET_SAMPLES[0], AUGMENTATION_METHOD)\n",
    "df_pol1 = augment_class(df, 1, TARGET_SAMPLES[1], AUGMENTATION_METHOD)\n",
    "df_pol2 = augment_class(df, 2, TARGET_SAMPLES[2], AUGMENTATION_METHOD)\n",
    "df_pol3 = df[df['Polarity'] == 3]  # Sin cambios (se aplicará undersampling)\n",
    "df_pol4 = df[df['Polarity'] == 4]  # Sin cambios (se aplicará undersampling)\n",
    "print(f\"  Polaridad 4: {len(df_pol3):,} (se aplicará undersampling)\")\n",
    "print(f\"  Polaridad 5: {len(df_pol4):,} (se aplicará undersampling)\\n\")\n",
    "\n",
    "df_augmented = pd.concat([df_pol0, df_pol1, df_pol2, df_pol3, df_pol4], ignore_index=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RESUMEN DESPUÉS DE AUGMENTATION\")\n",
    "print(\"=\" * 70)\n",
    "for pol in sorted(df_augmented['Polarity'].unique()):\n",
    "    count = len(df_augmented[df_augmented['Polarity'] == pol])\n",
    "    print(f\"  Polaridad {pol+1}: {count:,}\")\n",
    "print(f\"\\nTotal: {len(df_augmented):,}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9a0649",
   "metadata": {},
   "source": [
    "### 2.1. Funciones EDA (Easy Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ac52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Palabras comunes para no reemplazar\n",
    "STOP_WORDS = {'el', 'la', 'de', 'que', 'y', 'a', 'en', 'un', 'ser', 'se', 'no', 'haber', \n",
    "              'por', 'con', 'su', 'para', 'como', 'estar', 'tener', 'le', 'lo', 'todo',\n",
    "              'pero', 'más', 'hacer', 'o', 'poder', 'decir', 'este', 'ir', 'otro', 'ese',\n",
    "              'si', 'me', 'ya', 'ver', 'porque', 'dar', 'cuando', 'él', 'muy', 'sin',\n",
    "              'vez', 'mucho', 'saber', 'qué', 'sobre', 'mi', 'alguno', 'mismo', 'yo',\n",
    "              'también', 'hasta', 'año', 'dos', 'querer', 'entre', 'así', 'primero',\n",
    "              'desde', 'grande', 'eso', 'ni', 'nos', 'llegar', 'pasar', 'tiempo', 'ella',\n",
    "              'sí', 'día', 'uno', 'bien', 'poco', 'deber', 'entonces', 'poner', 'cosa',\n",
    "              'tanto', 'hombre', 'parecer', 'nuestro', 'tan', 'donde', 'ahora', 'parte',\n",
    "              'después', 'vida', 'quedar', 'siempre', 'creer', 'hablar', 'llevar', 'dejar',\n",
    "              'nada', 'cada', 'seguir', 'menos', 'nuevo', 'encontrar', 'algo', 'solo',\n",
    "              'decir', 'ni', 'tal', 'cómo', 'quien', 'mientras', 'durante', 'cual'}\n",
    "\n",
    "# Sinónimos básicos en español para augmentation\n",
    "SYNONYMS = {\n",
    "    'bueno': ['excelente', 'genial', 'estupendo', 'magnífico', 'fantástico'],\n",
    "    'malo': ['pésimo', 'horrible', 'terrible', 'desagradable', 'deplorable'],\n",
    "    'bonito': ['hermoso', 'lindo', 'bello', 'precioso', 'encantador'],\n",
    "    'feo': ['horrible', 'desagradable', 'espantoso', 'horroroso'],\n",
    "    'grande': ['enorme', 'gigante', 'inmenso', 'vasto', 'amplio'],\n",
    "    'pequeño': ['chico', 'diminuto', 'reducido', 'minúsculo'],\n",
    "    'rápido': ['veloz', 'ágil', 'raudo', 'presto'],\n",
    "    'lento': ['pausado', 'despacio', 'calmado'],\n",
    "    'limpio': ['pulcro', 'impoluto', 'aseado', 'impecable'],\n",
    "    'sucio': ['inmundo', 'mugriento', 'desaseado'],\n",
    "    'caro': ['costoso', 'oneroso', 'elevado'],\n",
    "    'barato': ['económico', 'accesible', 'módico'],\n",
    "    'rico': ['delicioso', 'sabroso', 'exquisito', 'apetitoso'],\n",
    "    'horrible': ['espantoso', 'terrible', 'horroroso', 'atroz'],\n",
    "    'increíble': ['asombroso', 'sorprendente', 'impresionante', 'extraordinario'],\n",
    "    'perfecto': ['ideal', 'impecable', 'excelente', 'óptimo'],\n",
    "    'terrible': ['espantoso', 'horrible', 'horroroso', 'pésimo'],\n",
    "    'maravilloso': ['estupendo', 'fantástico', 'extraordinario', 'magnífico'],\n",
    "    'agradable': ['placentero', 'grato', 'ameno', 'confortable'],\n",
    "    'desagradable': ['molesto', 'incómodo', 'antipático', 'fastidioso'],\n",
    "}\n",
    "\n",
    "def synonym_replacement(words, n=1):\n",
    "    \"\"\"Reemplaza n palabras con sinónimos\"\"\"\n",
    "    new_words = words.copy()\n",
    "    random_word_list = [word for word in words if word.lower() not in STOP_WORDS]\n",
    "    random.shuffle(random_word_list)\n",
    "    \n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        if random_word.lower() in SYNONYMS:\n",
    "            synonym = random.choice(SYNONYMS[random_word.lower()])\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "    \n",
    "    return new_words\n",
    "\n",
    "def random_insertion(words, n=1):\n",
    "    \"\"\"Inserta n palabras aleatorias de sinónimos\"\"\"\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        add_word(new_words)\n",
    "    return new_words\n",
    "\n",
    "def add_word(new_words):\n",
    "    synonyms_flat = [syn for syns in SYNONYMS.values() for syn in syns]\n",
    "    random_synonym = random.choice(synonyms_flat)\n",
    "    random_idx = random.randint(0, len(new_words)-1)\n",
    "    new_words.insert(random_idx, random_synonym)\n",
    "\n",
    "def random_swap(words, n=1):\n",
    "    \"\"\"Intercambia n pares de palabras\"\"\"\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        if len(new_words) >= 2:\n",
    "            idx1, idx2 = random.sample(range(len(new_words)), 2)\n",
    "            new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\n",
    "    return new_words\n",
    "\n",
    "def random_deletion(words, p=0.1):\n",
    "    \"\"\"Elimina palabras con probabilidad p\"\"\"\n",
    "    if len(words) == 1:\n",
    "        return words\n",
    "    \n",
    "    new_words = [word for word in words if random.uniform(0, 1) > p]\n",
    "    if len(new_words) == 0:\n",
    "        return [random.choice(words)]\n",
    "    \n",
    "    return new_words\n",
    "\n",
    "def eda(sentence, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, p_rd=0.1, num_aug=1):\n",
    "    \"\"\"\n",
    "    Easy Data Augmentation\n",
    "    alpha_sr: porcentaje de palabras para synonym replacement\n",
    "    alpha_ri: porcentaje de palabras para random insertion\n",
    "    alpha_rs: porcentaje de palabras para random swap\n",
    "    p_rd: probabilidad de random deletion\n",
    "    num_aug: número de frases aumentadas por frase original\n",
    "    \"\"\"\n",
    "    words = sentence.split()\n",
    "    num_words = len(words)\n",
    "    \n",
    "    augmented_sentences = []\n",
    "    \n",
    "    for _ in range(num_aug):\n",
    "        a_words = words.copy()\n",
    "        \n",
    "        # Synonym Replacement\n",
    "        num_sr = max(1, int(alpha_sr * num_words))\n",
    "        a_words = synonym_replacement(a_words, num_sr)\n",
    "        \n",
    "        # Random Insertion\n",
    "        num_ri = max(1, int(alpha_ri * num_words))\n",
    "        a_words = random_insertion(a_words, num_ri)\n",
    "        \n",
    "        # Random Swap\n",
    "        num_rs = max(1, int(alpha_rs * num_words))\n",
    "        a_words = random_swap(a_words, num_rs)\n",
    "        \n",
    "        # Random Deletion\n",
    "        a_words = random_deletion(a_words, p_rd)\n",
    "        \n",
    "        augmented_sentences.append(' '.join(a_words))\n",
    "    \n",
    "    return augmented_sentences\n",
    "\n",
    "print(\"✓ Funciones EDA cargadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5593348",
   "metadata": {},
   "source": [
    "### 2.2. Funciones Back-Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052117d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_backtranslation_models():\n",
    "    \"\"\"Carga los modelos de traducción solo si se necesitan\"\"\"\n",
    "    from transformers import MarianMTModel, MarianTokenizer\n",
    "    \n",
    "    print(\"Cargando modelos de traducción...\")\n",
    "    device = BACKTRANSLATION_CONFIG['device']\n",
    "    \n",
    "    models = {}\n",
    "    tokenizers = {}\n",
    "    \n",
    "    # Español → Inglés\n",
    "    models['es-en'] = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-es-en').to(device)\n",
    "    tokenizers['es-en'] = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-es-en')\n",
    "    \n",
    "    # Inglés → Español\n",
    "    models['en-es'] = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-es').to(device)\n",
    "    tokenizers['en-es'] = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-es')\n",
    "    \n",
    "    # Si hay más idiomas configurados\n",
    "    for lang in BACKTRANSLATION_CONFIG['languages']:\n",
    "        if lang == 'en':\n",
    "            continue\n",
    "        # Español → Idioma\n",
    "        models[f'es-{lang}'] = MarianMTModel.from_pretrained(f'Helsinki-NLP/opus-mt-es-{lang}').to(device)\n",
    "        tokenizers[f'es-{lang}'] = MarianTokenizer.from_pretrained(f'Helsinki-NLP/opus-mt-es-{lang}')\n",
    "        \n",
    "        # Idioma → Español\n",
    "        models[f'{lang}-es'] = MarianMTModel.from_pretrained(f'Helsinki-NLP/opus-mt-{lang}-es').to(device)\n",
    "        tokenizers[f'{lang}-es'] = MarianTokenizer.from_pretrained(f'Helsinki-NLP/opus-mt-{lang}-es')\n",
    "    \n",
    "    print(\"✓ Modelos de traducción cargados\")\n",
    "    return models, tokenizers\n",
    "\n",
    "def translate_text(text, model, tokenizer, device='cpu'):\n",
    "    \"\"\"Traduce un texto usando un modelo específico\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    translated = model.generate(**inputs, max_length=512)\n",
    "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "def back_translate(text, source_lang='es', target_langs=['en'], models=None, tokenizers=None, device='cpu'):\n",
    "    \"\"\"\n",
    "    Realiza back-translation a través de múltiples idiomas\n",
    "    \n",
    "    Args:\n",
    "        text: Texto original en español\n",
    "        source_lang: Idioma de origen (default: 'es')\n",
    "        target_langs: Lista de idiomas intermedios\n",
    "        models: Diccionario de modelos pre-cargados\n",
    "        tokenizers: Diccionario de tokenizers pre-cargados\n",
    "    \n",
    "    Returns:\n",
    "        Lista de textos traducidos (uno por cada idioma intermedio)\n",
    "    \"\"\"\n",
    "    augmented = []\n",
    "    \n",
    "    for target_lang in target_langs:\n",
    "        try:\n",
    "            # Español → Idioma intermedio\n",
    "            intermediate = translate_text(\n",
    "                text, \n",
    "                models[f'{source_lang}-{target_lang}'], \n",
    "                tokenizers[f'{source_lang}-{target_lang}'],\n",
    "                device\n",
    "            )\n",
    "            \n",
    "            # Idioma intermedio → Español\n",
    "            back_translated = translate_text(\n",
    "                intermediate,\n",
    "                models[f'{target_lang}-{source_lang}'],\n",
    "                tokenizers[f'{target_lang}-{source_lang}'],\n",
    "                device\n",
    "            )\n",
    "            \n",
    "            augmented.append(back_translated)\n",
    "        except Exception as e:\n",
    "            print(f\"    ⚠️  Error traduciendo a {target_lang}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "print(\"✓ Funciones Back-Translation cargadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25fea6b",
   "metadata": {},
   "source": [
    "## 4. Undersampling de Clase Mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1c80fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "APLICANDO UNDERSAMPLING A CLASES MAYORITARIAS\n",
      "======================================================================\n",
      "\n",
      "Objetivos de balanceo:\n",
      "  Polaridad 1: 30,000 → 30,000 ✓ Sin cambios\n",
      "  Polaridad 2: 30,000 → 30,000 ✓ Sin cambios\n",
      "  Polaridad 3: 40,000 → 40,000 ✓ Sin cambios\n",
      "  Polaridad 4: 45,034 → 40,000 ↓ Undersampling\n",
      "  Polaridad 5: 136,561 → 50,000 ↓ Undersampling\n",
      "\n",
      "======================================================================\n",
      "DATASET FINAL BALANCEADO\n",
      "======================================================================\n",
      "  Polaridad 1: 30,000 (15.79%) ███████\n",
      "  Polaridad 2: 30,000 (15.79%) ███████\n",
      "  Polaridad 3: 40,000 (21.05%) ██████████\n",
      "  Polaridad 4: 40,000 (21.05%) ██████████\n",
      "  Polaridad 5: 50,000 (26.32%) █████████████\n",
      "\n",
      "Total final: 190,000\n",
      "======================================================================\n",
      "  Polaridad 3: 40,000 (21.05%) ██████████\n",
      "  Polaridad 4: 40,000 (21.05%) ██████████\n",
      "  Polaridad 5: 50,000 (26.32%) █████████████\n",
      "\n",
      "Total final: 190,000\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"APLICANDO UNDERSAMPLING A CLASES MAYORITARIAS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Usar la estrategia de balanceo definida en configuración\n",
    "sampling_strategy = TARGET_SAMPLES\n",
    "\n",
    "print(\"\\nObjetivos de balanceo:\")\n",
    "for pol, target in sampling_strategy.items():\n",
    "    current = len(df_augmented[df_augmented['Polarity'] == pol])\n",
    "    change = \"↓ Undersampling\" if current > target else \"✓ Sin cambios\"\n",
    "    print(f\"  Polaridad {pol+1}: {current:,} → {target:,} {change}\")\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "df_balanced, _ = rus.fit_resample(df_augmented, df_augmented['Polarity'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATASET FINAL BALANCEADO\")\n",
    "print(\"=\" * 70)\n",
    "for pol in sorted(df_balanced['Polarity'].unique()):\n",
    "    count = len(df_balanced[df_balanced['Polarity'] == pol])\n",
    "    pct = (count / len(df_balanced)) * 100\n",
    "    bar = '█' * int(pct / 2)\n",
    "    print(f\"  Polaridad {pol+1}: {count:,} ({pct:5.2f}%) {bar}\")\n",
    "print(f\"\\nTotal final: {len(df_balanced):,}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f15b6",
   "metadata": {},
   "source": [
    "## 5. Generación de Embeddings con MiniLM (Rápido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c59b3cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando embeddings...\n",
      "Generando embeddings para 190,000 textos...\n",
      "Batch size: 128 | Total batches: 1485\n",
      "Modelo: paraphrase-multilingual-MiniLM-L12-v2 (384 dims)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09837b79791445e2b299531248a8b21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando batches:   0%|          | 0/1485 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack(embeddings)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerando embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_balanced\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m y_polarity \u001b[38;5;241m=\u001b[39m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPolarity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     24\u001b[0m y_type \u001b[38;5;241m=\u001b[39m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHotel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttractive\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRestaurant\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m})\u001b[38;5;241m.\u001b[39mvalues\n",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(texts, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), batch_size), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcesando batches\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     15\u001b[0m     batch \u001b[38;5;241m=\u001b[39m texts[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m---> 16\u001b[0m     batch_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_st\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(batch_embeddings)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack(embeddings)\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:1094\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m-> 1094\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1096\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:1175\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m   1169\u001b[0m             module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m   1170\u001b[0m         module_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1171\u001b[0m             key: value\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1173\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mforward_kwargs)\n\u001b[1;32m   1174\u001b[0m         }\n\u001b[0;32m-> 1175\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:261\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m trans_features \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_forward_params}\n\u001b[0;32m--> 261\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m token_embeddings \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    263\u001b[0m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token_embeddings\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1000\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    998\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1000\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1014\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:650\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    646\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m    648\u001b[0m layer_head_mask \u001b[38;5;241m=\u001b[39m head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/transformers/modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:558\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_value\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.58\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m     cache_position: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 558\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    567\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:488\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_value\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.58\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m     cache_position: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    487\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 488\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    498\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:363\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    351\u001b[0m         hidden_states,\n\u001b[1;32m    352\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m         cache_position,\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    360\u001b[0m bsz, tgt_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    362\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(bsz, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_head_size)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    364\u001b[0m )\n\u001b[1;32m    366\u001b[0m is_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    367\u001b[0m is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/Rest-Mex-Dataset-Analysis/lib/python3.10/site-packages/torch/nn/modules/linear.py:134\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Runs the forward pass.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Modelo más rápido: MiniLM multilingüe (384 dims vs 768 de BETO, ~100x más rápido)\n",
    "model_st = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', device=device)\n",
    "\n",
    "def get_embeddings(texts, batch_size=128):  # Batch size más grande para velocidad\n",
    "    embeddings = []\n",
    "\n",
    "    print(f\"Generando embeddings para {len(texts):,} textos...\")\n",
    "    print(f\"Batch size: {batch_size} | Total batches: {len(texts) // batch_size + 1}\")\n",
    "    print(f\"Modelo: paraphrase-multilingual-MiniLM-L12-v2 (384 dims)\")\n",
    "\n",
    "    # Sentence Transformers maneja el batching automáticamente y es mucho más rápido\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Procesando batches\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        batch_embeddings = model_st.encode(batch, convert_to_numpy=True, show_progress_bar=False)\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "print(\"Generando embeddings...\")\n",
    "X = get_embeddings(df_balanced['Review'].tolist())\n",
    "y_polarity = df_balanced['Polarity'].values\n",
    "y_type = df_balanced['Type'].map({'Hotel': 0, 'Attractive': 1, 'Restaurant': 2}).values\n",
    "\n",
    "print(f\"Shape embeddings: {X.shape}\")\n",
    "print(\"✓ Embeddings generados exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a69383",
   "metadata": {},
   "source": [
    "## 6. Exportar Embeddings a CSV (para uso en Scala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effc348",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_pol_train, y_pol_test, y_type_train, y_type_test = train_test_split(\n",
    "    X, y_polarity, y_type, test_size=0.2, random_state=42, stratify=y_polarity\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train):,} | Test: {len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd808a18",
   "metadata": {},
   "source": [
    "## 7. Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba782ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_pol_train, y_pol_test, y_type_train, y_type_test = train_test_split(\n",
    "    X, y_polarity, y_type, test_size=0.2, random_state=42, stratify=y_polarity\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train):,} | Test: {len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b26d29",
   "metadata": {},
   "source": [
    "## 8. Modelo Polaridad - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== ENTRENANDO MODELO POLARIDAD (Gradient Boosting) ===\")\n",
    "\n",
    "# Calcular class weights\n",
    "class_weights_pol = compute_class_weight('balanced', classes=np.unique(y_pol_train), y=y_pol_train)\n",
    "sample_weights = np.array([class_weights_pol[y] for y in y_pol_train])\n",
    "\n",
    "# Entrenar Gradient Boosting\n",
    "model_polarity = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_polarity.fit(X_train, y_pol_train, sample_weight=sample_weights)\n",
    "print(\"✓ Modelo entrenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe3dfd",
   "metadata": {},
   "source": [
    "## 9. Evaluación - Modelo Polaridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pol = model_polarity.predict(X_test)\n",
    "\n",
    "print(\"\\n=== RESULTADOS POLARIDAD ===\")\n",
    "print(classification_report(y_pol_test, y_pred_pol, target_names=['1', '2', '3', '4', '5']))\n",
    "print(f\"\\nF1-Macro: {f1_score(y_pol_test, y_pred_pol, average='macro'):.4f}\")\n",
    "print(f\"F1-Weighted: {f1_score(y_pol_test, y_pred_pol, average='weighted'):.4f}\")\n",
    "print(f\"\\nMatriz de Confusión:\\n{confusion_matrix(y_pol_test, y_pred_pol)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7045651f",
   "metadata": {},
   "source": [
    "## 10. Modelo Tipo - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7774d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== ENTRENANDO MODELO TIPO (Random Forest) ===\")\n",
    "\n",
    "# Calcular class weights\n",
    "class_weights_type = compute_class_weight('balanced', classes=np.unique(y_type_train), y=y_type_train)\n",
    "sample_weights_type = np.array([class_weights_type[y] for y in y_type_train])\n",
    "\n",
    "# Entrenar Random Forest\n",
    "model_type = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_type.fit(X_train, y_type_train, sample_weight=sample_weights_type)\n",
    "print(\"✓ Modelo entrenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37193917",
   "metadata": {},
   "source": [
    "## 11. Evaluación - Modelo Tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acfe7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_type = model_type.predict(X_test)\n",
    "\n",
    "print(\"\\n=== RESULTADOS TIPO ===\")\n",
    "print(classification_report(y_type_test, y_pred_type, target_names=['Hotel', 'Attractive', 'Restaurant']))\n",
    "print(f\"\\nF1-Macro: {f1_score(y_type_test, y_pred_type, average='macro'):.4f}\")\n",
    "print(f\"F1-Weighted: {f1_score(y_type_test, y_pred_type, average='weighted'):.4f}\")\n",
    "print(f\"\\nMatriz de Confusión:\\n{confusion_matrix(y_type_test, y_pred_type)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6d529b",
   "metadata": {},
   "source": [
    "## 12. Guardar Modelos y Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# EXPORTAR EMBEDDINGS A CSV\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPORTANDO EMBEDDINGS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Crear DataFrame con embeddings completos\n",
    "embedding_columns = [f'emb_{i}' for i in range(X.shape[1])]\n",
    "df_embeddings = pd.DataFrame(X, columns=embedding_columns)\n",
    "df_embeddings['polarity'] = y_polarity\n",
    "df_embeddings['type'] = df_balanced['Type'].values\n",
    "df_embeddings['review_text'] = df_balanced['Review'].values\n",
    "\n",
    "# Guardar embeddings completos\n",
    "df_embeddings.to_csv('embeddings_complete.csv', index=False)\n",
    "print(f\"✓ Guardado: embeddings_complete.csv ({len(df_embeddings):,} filas x {len(df_embeddings.columns)} columnas)\")\n",
    "\n",
    "# Crear versión con split train/test\n",
    "train_indices = np.arange(len(X))\n",
    "test_indices_mask = np.zeros(len(X), dtype=bool)\n",
    "test_size = int(0.2 * len(X))\n",
    "np.random.seed(42)\n",
    "test_indices_mask[np.random.choice(len(X), test_size, replace=False)] = True\n",
    "\n",
    "df_embeddings['split'] = 'train'\n",
    "df_embeddings.loc[test_indices_mask, 'split'] = 'test'\n",
    "\n",
    "df_embeddings.to_csv('embeddings_with_split.csv', index=False)\n",
    "print(f\"✓ Guardado: embeddings_with_split.csv (con columna 'split')\")\n",
    "\n",
    "# ==========================================\n",
    "# EXPORTAR MODELOS\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPORTANDO MODELOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Guardar modelos en formato pickle\n",
    "with open('model_polarity.pkl', 'wb') as f:\n",
    "    pickle.dump(model_polarity, f)\n",
    "print(\"✓ Guardado: model_polarity.pkl (Gradient Boosting)\")\n",
    "\n",
    "with open('model_type.pkl', 'wb') as f:\n",
    "    pickle.dump(model_type, f)\n",
    "print(\"✓ Guardado: model_type.pkl (Random Forest)\")\n",
    "\n",
    "# Guardar metadata\n",
    "metadata = {\n",
    "    'augmentation_method': AUGMENTATION_METHOD,\n",
    "    'polarity_model': 'GradientBoostingClassifier',\n",
    "    'type_model': 'RandomForestClassifier',\n",
    "    'embedding_dim': X.shape[1],\n",
    "    'embedding_model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'polarity_classes': 5,\n",
    "    'type_classes': 3,\n",
    "    'type_mapping': {'Hotel': 0, 'Attractive': 1, 'Restaurant': 2},\n",
    "    'target_samples': TARGET_SAMPLES,\n",
    "    'total_samples': len(df_balanced),\n",
    "    'train_samples': len(X_train),\n",
    "    'test_samples': len(X_test)\n",
    "}\n",
    "\n",
    "if AUGMENTATION_METHOD == 'eda':\n",
    "    metadata['eda_config'] = EDA_CONFIG\n",
    "elif AUGMENTATION_METHOD == 'backtranslation':\n",
    "    metadata['backtranslation_config'] = BACKTRANSLATION_CONFIG\n",
    "\n",
    "import json\n",
    "with open('models_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"✓ Guardado: models_metadata.json\")\n",
    "\n",
    "# ==========================================\n",
    "# RESUMEN FINAL\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ARCHIVOS GENERADOS PARA USO EN SCALA:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"  1. embeddings_complete.csv - Todos los embeddings con labels\")\n",
    "print(\"  2. embeddings_with_split.csv - Embeddings con columna train/test\")\n",
    "print(\"  3. model_polarity.pkl - Modelo de polaridad\")\n",
    "print(\"  4. model_type.pkl - Modelo de tipo\")\n",
    "print(\"  5. models_metadata.json - Metadata de los modelos\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n📊 Resumen:\")\n",
    "print(f\"  • Método augmentation: {AUGMENTATION_METHOD.upper()}\")\n",
    "print(f\"  • Total registros: {len(df_balanced):,}\")\n",
    "print(f\"  • Dimensiones embedding: {X.shape[1]}\")\n",
    "print(f\"  • Train: {len(X_train):,}\")\n",
    "print(f\"  • Test: {len(X_test):,}\")\n",
    "print(f\"  • F1-Macro Polaridad: {f1_score(y_pol_test, y_pred_pol, average='macro'):.4f}\")\n",
    "print(f\"  • F1-Macro Tipo: {f1_score(y_pred_type, y_pred_type, average='macro'):.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rest-Mex-Dataset-Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
