"""
An√°lisis Exploratorio del Dataset Rest-Mex
==========================================
Este script realiza un an√°lisis exhaustivo de las distribuciones de clases
para determinar la mejor estrategia de balanceo.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

# Configuraci√≥n de visualizaci√≥n
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (15, 10)

# Cargar datos
print("=" * 80)
print("AN√ÅLISIS EXPLORATORIO - DATASET REST-MEX")
print("=" * 80)

df = pd.read_csv('data/Rest-Mex_2025_train.csv')

print(f"\nüìä INFORMACI√ìN GENERAL")
print(f"{'‚îÄ' * 80}")
print(f"Total de registros: {len(df):,}")
print(f"Columnas: {list(df.columns)}")
print(f"\nTipos de datos:")
print(df.dtypes)
print(f"\nValores nulos:")
print(df.isnull().sum())

# Identificar la columna de texto - Priorizar 'Review' sobre 'Title'
text_columns = [col for col in df.columns if df[col].dtype == 'object' and col not in ['polaridad', 'tipo_atraccion', 'type', 'attraction_type', 'Polarity', 'Type']]

# Buscar espec√≠ficamente columnas de review/opinion
review_cols = [col for col in text_columns if 'review' in col.lower() or 'opinion' in col.lower() or 'text' in col.lower()]
title_cols = [col for col in text_columns if 'title' in col.lower() or 'titulo' in col.lower()]

if review_cols:
    text_col = review_cols[0]
    print(f"\nüìù Columna de texto (REVIEW) identificada: '{text_col}'")
elif title_cols:
    text_col = title_cols[0]
    print(f"\n‚ö†Ô∏è Solo se encontr√≥ columna de T√çTULO: '{text_col}' (no es la rese√±a completa)")
elif text_columns:
    text_col = text_columns[0]
    print(f"\nüìù Columna de texto identificada: '{text_col}'")
else:
    text_col = None
    print("\n‚ö†Ô∏è No se identific√≥ columna de texto autom√°ticamente")

# ==============================================================================
# 1. AN√ÅLISIS DE POLARIDAD
# ==============================================================================
print(f"\n\n{'=' * 80}")
print("1Ô∏è‚É£  AN√ÅLISIS DE POLARIDAD")
print(f"{'=' * 80}")

# Buscar columna de polaridad (puede tener diferentes nombres)
polarity_cols = [col for col in df.columns if 'polari' in col.lower() or 'rating' in col.lower() or 'star' in col.lower()]
if polarity_cols:
    polarity_col = polarity_cols[0]
else:
    # Intentar encontrar por valores √∫nicos (1-5)
    for col in df.columns:
        if df[col].dtype in ['int64', 'float64'] and df[col].nunique() <= 5 and df[col].min() >= 1 and df[col].max() <= 5:
            polarity_col = col
            break

print(f"\nColumna de polaridad: '{polarity_col}'")

polarity_counts = df[polarity_col].value_counts().sort_index()
polarity_pcts = df[polarity_col].value_counts(normalize=True).sort_index() * 100

print(f"\nüìà Distribuci√≥n de Polaridad:")
print(f"{'‚îÄ' * 80}")
for rating in sorted(df[polarity_col].unique()):
    count = polarity_counts.get(rating, 0)
    pct = polarity_pcts.get(rating, 0)
    bar = '‚ñà' * int(pct / 2)
    print(f"  Polaridad {rating}: {count:>6,} ({pct:>5.2f}%) {bar}")

# Calcular imbalance ratio
max_class = polarity_counts.max()
min_class = polarity_counts.min()
imbalance_ratio = max_class / min_class

print(f"\n‚öñÔ∏è  M√âTRICAS DE DESBALANCEO:")
print(f"  ‚Ä¢ Clase mayoritaria: {polarity_counts.idxmax()} con {max_class:,} muestras")
print(f"  ‚Ä¢ Clase minoritaria: {polarity_counts.idxmin()} con {min_class:,} muestras")
print(f"  ‚Ä¢ Ratio de desbalanceo: {imbalance_ratio:.2f}:1")

if imbalance_ratio > 10:
    print(f"  ‚ö†Ô∏è  DESBALANCEO SEVERO (>10:1) - Se recomienda t√©cnicas agresivas")
elif imbalance_ratio > 5:
    print(f"  ‚ö†Ô∏è  DESBALANCEO MODERADO (>5:1) - Se recomienda balanceo")
else:
    print(f"  ‚úì  DESBALANCEO LEVE (<5:1) - Class weights pueden ser suficientes")

# ==============================================================================
# 2. AN√ÅLISIS DE TIPO DE ATRACCI√ìN
# ==============================================================================
print(f"\n\n{'=' * 80}")
print("2Ô∏è‚É£  AN√ÅLISIS DE TIPO DE ATRACCI√ìN")
print(f"{'=' * 80}")

# Buscar columna de tipo
type_cols = [col for col in df.columns if 'tipo' in col.lower() or 'type' in col.lower() or 'atraccion' in col.lower() or 'attraction' in col.lower()]
if type_cols:
    type_col = type_cols[0]
else:
    # Buscar columna categ√≥rica con pocos valores √∫nicos
    for col in df.columns:
        if col != polarity_col and df[col].dtype == 'object' and df[col].nunique() <= 5:
            type_col = col
            break

print(f"\nColumna de tipo: '{type_col}'")

type_counts = df[type_col].value_counts()
type_pcts = df[type_col].value_counts(normalize=True) * 100

print(f"\nüìà Distribuci√≥n de Tipo de Atracci√≥n:")
print(f"{'‚îÄ' * 80}")
for tipo in type_counts.index:
    count = type_counts[tipo]
    pct = type_pcts[tipo]
    bar = '‚ñà' * int(pct / 2)
    print(f"  {tipo:20s}: {count:>6,} ({pct:>5.2f}%) {bar}")

# Calcular imbalance ratio
max_type = type_counts.max()
min_type = type_counts.min()
type_imbalance = max_type / min_type

print(f"\n‚öñÔ∏è  M√âTRICAS DE DESBALANCEO:")
print(f"  ‚Ä¢ Clase mayoritaria: {type_counts.idxmax()} con {max_type:,} muestras")
print(f"  ‚Ä¢ Clase minoritaria: {type_counts.idxmin()} con {min_type:,} muestras")
print(f"  ‚Ä¢ Ratio de desbalanceo: {type_imbalance:.2f}:1")

if type_imbalance > 5:
    print(f"  ‚ö†Ô∏è  DESBALANCEO SIGNIFICATIVO - Considerar balanceo")
elif type_imbalance > 2:
    print(f"  ‚ö†Ô∏è  DESBALANCEO LEVE - Class weights recomendados")
else:
    print(f"  ‚úì  DISTRIBUCI√ìN ACEPTABLE")

# ==============================================================================
# 3. AN√ÅLISIS CRUZADO
# ==============================================================================
print(f"\n\n{'=' * 80}")
print("3Ô∏è‚É£  AN√ÅLISIS CRUZADO (Polaridad √ó Tipo)")
print(f"{'=' * 80}")

cross_tab = pd.crosstab(df[polarity_col], df[type_col], margins=True)
print("\nüìä Tabla de Contingencia (conteos):")
print(cross_tab)

cross_tab_pct = pd.crosstab(df[polarity_col], df[type_col], normalize='all') * 100
print("\nüìä Tabla de Contingencia (porcentajes):")
print(cross_tab_pct.round(2))

# Identificar combinaciones raras
print(f"\n‚ö†Ô∏è  COMBINACIONES CON <1% DE LOS DATOS:")
for pol in df[polarity_col].unique():
    for tipo in df[type_col].unique():
        count = len(df[(df[polarity_col] == pol) & (df[type_col] == tipo)])
        pct = (count / len(df)) * 100
        if pct < 1 and count > 0:
            print(f"  ‚Ä¢ Polaridad {pol} + {tipo}: {count} muestras ({pct:.2f}%)")

# ==============================================================================
# 4. AN√ÅLISIS DE TEXTO
# ==============================================================================
print(f"\n\n{'=' * 80}")
print("4Ô∏è‚É£  AN√ÅLISIS DE TEXTO")
print(f"{'=' * 80}")

# Analizar ambas columnas: Title y Review
for col in ['Title', 'Review']:
    if col in df.columns:
        print(f"\n{'‚îÄ' * 80}")
        print(f"üìù An√°lisis de columna: '{col}'")
        print(f"{'‚îÄ' * 80}")
        
        df[f'{col}_length'] = df[col].astype(str).str.len()
        df[f'{col}_words'] = df[col].astype(str).str.split().str.len()
        
        print(f"\nüìä Estad√≠sticas de Longitud:")
        print(f"  Caracteres:")
        print(f"    ‚Ä¢ Media: {df[f'{col}_length'].mean():.1f}")
        print(f"    ‚Ä¢ Mediana: {df[f'{col}_length'].median():.1f}")
        print(f"    ‚Ä¢ Std: {df[f'{col}_length'].std():.1f}")
        print(f"    ‚Ä¢ Min: {df[f'{col}_length'].min()}")
        print(f"    ‚Ä¢ Max: {df[f'{col}_length'].max()}")
        print(f"    ‚Ä¢ Q1 (25%): {df[f'{col}_length'].quantile(0.25):.1f}")
        print(f"    ‚Ä¢ Q3 (75%): {df[f'{col}_length'].quantile(0.75):.1f}")
        
        print(f"\n  Palabras:")
        print(f"    ‚Ä¢ Media: {df[f'{col}_words'].mean():.1f}")
        print(f"    ‚Ä¢ Mediana: {df[f'{col}_words'].median():.1f}")
        print(f"    ‚Ä¢ Std: {df[f'{col}_words'].std():.1f}")
        print(f"    ‚Ä¢ Min: {df[f'{col}_words'].min()}")
        print(f"    ‚Ä¢ Max: {df[f'{col}_words'].max()}")
        print(f"    ‚Ä¢ Q1 (25%): {df[f'{col}_words'].quantile(0.25):.1f}")
        print(f"    ‚Ä¢ Q3 (75%): {df[f'{col}_words'].quantile(0.75):.1f}")
        
        print(f"\nüìù Ejemplos de {col} por polaridad:")
        for pol in sorted(df[polarity_col].unique()):
            print(f"\n  Polaridad {pol}:")
            sample = df[df[polarity_col] == pol][col].iloc[0]
            if len(str(sample)) > 200:
                print(f"    {sample[:200]}...")
            else:
                print(f"    {sample}")

# Determinar cu√°l usar
if 'Review' in df.columns:
    text_col = 'Review'
    print(f"\n{'‚îÄ' * 80}")
    print(f"‚úÖ RECOMENDACI√ìN: Usar columna 'Review' para el modelo")
    print(f"   (contiene las rese√±as completas con m√°s contexto)")
    print(f"{'‚îÄ' * 80}")
elif 'Title' in df.columns:
    text_col = 'Title'
    print(f"\n{'‚îÄ' * 80}")
    print(f"‚ö†Ô∏è  Solo disponible columna 'Title' (t√≠tulos cortos)")
    print(f"{'‚îÄ' * 80}")

# ==============================================================================
# 5. RECOMENDACIONES INICIALES
# ==============================================================================
print(f"\n\n{'=' * 80}")
print("5Ô∏è‚É£  RECOMENDACIONES INICIALES")
print(f"{'=' * 80}")

print(f"\nüí° ESTRATEGIA SUGERIDA PARA POLARIDAD:")
if imbalance_ratio > 20:
    print(f"  1. ‚ùå EVITAR SMOTE en embeddings (espacio muy dimensional)")
    print(f"  2. ‚úÖ Focal Loss (ideal para desbalanceo extremo)")
    print(f"  3. ‚úÖ Class weights agresivos")
    print(f"  4. ‚úÖ Undersampling moderado de clases mayoritarias (4-5)")
    print(f"  5. ‚ö†Ô∏è  Considerar agrupar clases: [1-2], [3], [4-5] si el negocio lo permite")
elif imbalance_ratio > 10:
    print(f"  1. ‚úÖ Class weights")
    print(f"  2. ‚úÖ Focal Loss o Weighted Cross-Entropy")
    print(f"  3. ü§î Undersampling moderado de clase mayoritaria")
    print(f"  4. ‚ùå SMOTE NO recomendado en embeddings")
elif imbalance_ratio > 5:
    print(f"  1. ‚úÖ Class weights (probablemente suficiente)")
    print(f"  2. ü§î Focal Loss si class weights no funciona")
else:
    print(f"  1. ‚úÖ Class weights ligeros")
    print(f"  2. ‚úÖ O ninguna t√©cnica (modelo puede aprender naturalmente)")

print(f"\nüí° ESTRATEGIA SUGERIDA PARA TIPO DE ATRACCI√ìN:")
if type_imbalance > 5:
    print(f"  1. ‚úÖ Class weights")
    print(f"  2. ü§î Undersampling leve")
elif type_imbalance > 2:
    print(f"  1. ‚úÖ Class weights")
else:
    print(f"  1. ‚úÖ No requiere balanceo especial")

print(f"\nüí° ARQUITECTURA SUGERIDA:")
print(f"  ‚Ä¢ Opci√≥n 1 (RECOMENDADA): Multi-task learning - Un modelo con 2 cabezas")
print(f"    - Comparte embeddings entre tareas")
print(f"    - M√°s eficiente y puede mejorar generalizaci√≥n")
print(f"  ‚Ä¢ Opci√≥n 2: Dos modelos separados")
print(f"    - M√°s simple de implementar y debuggear")
print(f"    - Permite optimizaci√≥n independiente")

print(f"\nüí° M√âTRICAS DE EVALUACI√ìN:")
print(f"  Para Polaridad: F1-Macro, Confusion Matrix, Recall por clase")
print(f"  Para Tipo: F1-Macro o Weighted (depende de importancia de clases)")

print(f"\n{'=' * 80}")
print("‚úÖ AN√ÅLISIS COMPLETADO")
print(f"{'=' * 80}\n")

# Guardar informaci√≥n para siguiente script
info = {
    'text_col': text_col,
    'polarity_col': polarity_col,
    'type_col': type_col,
    'total_samples': len(df),
    'polarity_imbalance': imbalance_ratio,
    'type_imbalance': type_imbalance,
    'polarity_distribution': polarity_counts.to_dict(),
    'type_distribution': type_counts.to_dict()
}

import json
with open('analysis_info.json', 'w') as f:
    json.dump(info, f, indent=2)

print("üìÅ Informaci√≥n guardada en: analysis_info.json")
