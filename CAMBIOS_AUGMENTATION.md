# Cambios: Soporte Multi-M√©todo para Data Augmentation

## üéØ Objetivo

A√±adir flexibilidad al notebook para permitir seleccionar entre dos m√©todos de data augmentation:
- **EDA** (Easy Data Augmentation): R√°pido y eficiente para CPU
- **Back-Translation**: M√°s preciso pero requiere m√°s recursos

## üìù Cambios Realizados

### 1. Nueva Celda de Configuraci√≥n (Secci√≥n 1.5)

A√±adida celda de configuraci√≥n centralizada que permite:
- Seleccionar m√©todo: `AUGMENTATION_METHOD = 'eda'` o `'backtranslation'`
- Configurar par√°metros de EDA
- Configurar idiomas y device para back-translation
- Definir estrategia de balanceo (`TARGET_SAMPLES`)

```python
AUGMENTATION_METHOD = 'eda'  # o 'backtranslation'

EDA_CONFIG = {
    'alpha_sr': 0.15,
    'alpha_ri': 0.15,
    'alpha_rs': 0.15,
    'p_rd': 0.1
}

BACKTRANSLATION_CONFIG = {
    'languages': ['en', 'fr', 'de'],
    'device': 'cpu'
}

TARGET_SAMPLES = {
    0: 30000, 1: 30000, 2: 40000, 3: 40000, 4: 50000
}
```

### 2. Reorganizaci√≥n de Funciones (Secci√≥n 2)

**Antes:** Todo el c√≥digo EDA estaba en una sola celda gigante

**Ahora:** Separado en subsecciones:
- **Secci√≥n 2.1**: Funciones EDA (STOP_WORDS, SYNONYMS, eda(), synonym_replacement(), etc.)
- **Secci√≥n 2.2**: Funciones Back-Translation (load_backtranslation_models(), translate_text(), back_translate())

### 3. Funci√≥n Unificada de Augmentation (Secci√≥n 3)

Nueva funci√≥n `augment_class()` que:
- Recibe par√°metro `method` ('eda' o 'backtranslation')
- Selecciona autom√°ticamente el m√©todo seg√∫n configuraci√≥n
- Maneja la carga de modelos de traducci√≥n (lazy loading)
- Usa configuraciones de `EDA_CONFIG` o `BACKTRANSLATION_CONFIG`

```python
def augment_class(df, polarity, target_size, method='eda'):
    """Aumenta una clase usando el m√©todo especificado"""
    if method == 'eda':
        # Usa funciones EDA
        aug_texts = eda(row['Review'], **EDA_CONFIG, num_aug=1)
    elif method == 'backtranslation':
        # Carga modelos (solo primera vez) y traduce
        aug_texts = back_translate(row['Review'], ...)
```

### 4. Undersampling Actualizado (Secci√≥n 4)

- Ahora usa `TARGET_SAMPLES` de la configuraci√≥n
- C√≥digo m√°s limpio y mantenible

### 5. Renumeraci√≥n de Secciones

| Antes | Ahora | Contenido |
|-------|-------|-----------|
| - | 1.5 | Configuraci√≥n de Data Augmentation |
| 2 | 2 | Funciones de Data Augmentation |
| - | 2.1 | Funciones EDA |
| - | 2.2 | Funciones Back-Translation |
| 3 | 3 | Aplicar Data Augmentation |
| 4 | 4 | Undersampling |
| 5 | 5 | Generaci√≥n de Embeddings |
| 6 | 6 | Exportar Embeddings a CSV |
| 7 | 7 | Split Train/Test |
| 8 | 8 | Modelo Polaridad |
| 9 | 9 | Evaluaci√≥n Polaridad |
| 10 | 10 | Modelo Tipo |
| 11 | 11 | Evaluaci√≥n Tipo |
| 12 | 12 | Guardar Modelos y Embeddings |

### 6. Metadata Actualizada

El archivo `models_metadata.json` ahora incluye:
```json
{
  "augmentation_method": "eda",
  "eda_config": {...},  // o "backtranslation_config": {...}
  "target_samples": {...},
  ...
}
```

### 7. Requirements Actualizados

A√±adido comentario en `requirements.txt`:
```
# Back-Translation (opcional - solo si usas AUGMENTATION_METHOD='backtranslation')
# torch>=2.0.0
# transformers>=4.21.0
# sacremoses>=0.0.53
```

### 8. Documentaci√≥n

Nuevos archivos:
- `README_AUGMENTATION.md`: Gu√≠a completa con ejemplos, comparaciones y troubleshooting

## üöÄ Uso

### Opci√≥n 1: EDA (Recomendado para CPU, r√°pido)

1. En celda 1.5, configurar:
```python
AUGMENTATION_METHOD = 'eda'
```

2. Ejecutar notebook normalmente
3. Tiempo estimado: ~15-20 minutos total

### Opci√≥n 2: Back-Translation (GPU recomendado, m√°s preciso)

1. Instalar dependencias:
```bash
pip install torch transformers sacremoses
```

2. En celda 1.5, configurar:
```python
AUGMENTATION_METHOD = 'backtranslation'
BACKTRANSLATION_CONFIG = {
    'languages': ['en'],  # Solo ingl√©s para velocidad
    'device': 'cuda'  # o 'cpu' si no hay GPU
}
```

3. Ejecutar notebook
4. Tiempo estimado: ~2-4 horas en CPU, ~30-60 min en GPU

## üìä Comparaci√≥n

| Aspecto | EDA | Back-Translation |
|---------|-----|------------------|
| **Tiempo (50K samples)** | ~5-10 min | ~2-4 horas (CPU) |
| **Memoria** | ~2 GB | ~8-12 GB |
| **GPU** | No necesaria | Recomendada |
| **Dependencias** | M√≠nimas | torch, transformers |
| **Calidad** | Buena | Excelente |

## üéì Ventajas del Nuevo Dise√±o

1. **Flexibilidad**: Cambiar m√©todo editando 1 l√≠nea
2. **Mantenibilidad**: C√≥digo organizado en funciones separadas
3. **Escalabilidad**: F√°cil a√±adir nuevos m√©todos
4. **Documentaci√≥n**: Metadata incluye m√©todo usado
5. **Performance**: Lazy loading de modelos (solo carga si necesario)

## ‚öôÔ∏è Arquitectura

```
Configuraci√≥n (1.5)
    ‚Üì
Funciones (2.1, 2.2)
    ‚Üì
augment_class() ‚Üê Selecciona m√©todo
    ‚Üì
Dataset Balanceado (3, 4)
    ‚Üì
Embeddings (5)
    ‚Üì
Modelos (6-11)
    ‚Üì
Export (12)
```

## üîÑ Migraci√≥n desde Versi√≥n Anterior

Si est√°s usando la versi√≥n anterior del notebook:

1. **No necesitas cambiar nada** para usar EDA (comportamiento por defecto)
2. Para cambiar a back-translation:
   - Instalar dependencias
   - Cambiar `AUGMENTATION_METHOD = 'backtranslation'`
3. Tus archivos de salida seguir√°n siendo compatibles con Scala

## üì¶ Archivos Afectados

- ‚úÖ `02_model_pipeline.ipynb` - Restructurado con soporte multi-m√©todo
- ‚úÖ `requirements.txt` - A√±adidas dependencias opcionales comentadas
- ‚úÖ `README_AUGMENTATION.md` - Nueva gu√≠a completa
- ‚úÖ `CAMBIOS_AUGMENTATION.md` - Este archivo

## ‚úÖ Testing

Ambos m√©todos fueron dise√±ados para producir el mismo formato de salida:
- `embeddings_complete.csv`
- `embeddings_with_split.csv`
- `model_polarity.pkl`
- `model_type.pkl`
- `models_metadata.json`

La √∫nica diferencia es la calidad/diversidad del texto augmentado.

## üêõ Troubleshooting

Ver `README_AUGMENTATION.md` secci√≥n "Troubleshooting" para soluciones a problemas comunes.
